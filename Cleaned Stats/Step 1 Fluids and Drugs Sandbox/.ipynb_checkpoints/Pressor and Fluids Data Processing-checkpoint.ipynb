{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e759518",
   "metadata": {},
   "source": [
    "\n",
    "Summary of Code Function:\n",
    "\n",
    "This Python script processes Excel files containing medical data related to vasopressin and norepinephrine administration. The script assumes a folder structure where raw data is stored in Excel files. It performs several data processing steps, including:\n",
    "\n",
    "- 1- Listing Excel Files: It identifies Excel files in a specified folder.\n",
    "\n",
    "- 2- Reading Excel Files: It reads each identified Excel file, extracting data into Pandas DataFrames.\n",
    "\n",
    "- 3- Counting Vasopressin Occurrences: It defines a function to count occurrences of vasopressin between different time points.\n",
    "\n",
    "- 4- Processing Excel Data: It processes each DataFrame extracted from Excel files, converting time data, extracting relevant information, and aggregating vasopressin occurrences.\n",
    "\n",
    "- 5- Sorting and Reordering Sheets: It sorts and reorders the processed data sheets based on numerical information extracted from their names.\n",
    "\n",
    "- 6-Merging Data: It merges processed data with another Excel file containing information about vasopressin and norepinephrine administration, multiplying values where columns match and calculating cumulative vasopressin doses.\n",
    "\n",
    "- 7-Writing Processed Data: It writes the processed data into a new Excel file with additional columns indicating total and cumulative vasopressin doses.\n",
    "\n",
    "Assumptions:\n",
    "\n",
    "- Data is organized in a folder structure, with each Excel file representing a distinct dataset.\n",
    "- Time points for data analysis are predefined.\n",
    "- The script assumes specific column names and formats within the Excel files, such as 'Study Time(sec)', 'Cumulative Volume', and 'Cumulative (Nor)epi Dose'.\n",
    "- There are no missing values in critical columns after data conversion.\n",
    "- The script assumes that each Excel file contains relevant data for analysis and does not perform extensive error checking for missing files or corrupted data.\n",
    "\n",
    "Data Processing Technique:\n",
    "\n",
    "The script primarily relies on Pandas, a Python library for data manipulation and analysis. It reads data from Excel files into Pandas DataFrames, performs data type conversion, filtering, aggregation, and merging operations to derive meaningful insights. Additionally, it utilizes basic file system operations provided by the os module for file listing and path manipulation. The script also employs regular expressions (re module) to extract numerical information from sheet names for sorting purposes. Overall, the script utilizes a combination of data manipulation techniques provided by Pandas and basic file handling functionalities to process and analyze medical data efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a841b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def list_excel_files(folder_path):\n",
    "    excel_files = [file for file in os.listdir(folder_path) if file.endswith('.xlsx')]\n",
    "    return excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661f3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_excel_files(folder_path, excel_files):\n",
    "    dataframes = {}\n",
    "    for file in excel_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        # Use the name without extension as the DataFrame name\n",
    "        dataframe_name = os.path.splitext(file)[0]\n",
    "        # Read the Excel file and store it in the dictionary\n",
    "        dataframes[dataframe_name] = pd.read_excel(file_path)\n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee6f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count Vasopressin occurrences between the previous time point and the current time point\n",
    "def count_vasopressin_before(df, time_points, time):\n",
    "    if time == 0:\n",
    "        return pd.Series([0, 0, 0, 0], index=[0, 1, 2, 3])\n",
    "    else:\n",
    "        prev_time_index = max(i for i, tp in enumerate(time_points) if tp < time)\n",
    "        prev_time = time_points[prev_time_index]\n",
    "        before_time_data = df[(df['Study Time(sec)'] > prev_time) & (df['Study Time(sec)'] <= time)]\n",
    "        if before_time_data.empty:\n",
    "            return pd.Series([0, 0, 0, 0], index=[0, 1, 2, 3])\n",
    "        else:\n",
    "            return before_time_data['Vasopressin'].value_counts().reindex([0, 1, 2, 3], fill_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db7fee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Process data from each Excel file and save to \"Processed Data.xlsx\"\n",
    "# def process_excel(filename, df):\n",
    "#     # Convert Time column to minutes\n",
    "#     df['Study Time(sec)'] /= 60\n",
    "def process_excel(filename, df):\n",
    "    # Convert 'Study Time(sec)' column to numeric type\n",
    "    df['Study Time(sec)'] = pd.to_numeric(df['Study Time(sec)'], errors='coerce')\n",
    "    \n",
    "    # Check for any NaN values after conversion\n",
    "    if df['Study Time(sec)'].isnull().any():\n",
    "        # Handle NaN values as needed, e.g., by filling with zeros\n",
    "        df['Study Time(sec)'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Convert Time column to minutes\n",
    "    df['Study Time(sec)'] /= 60\n",
    "\n",
    "    # Specify time points\n",
    "    time_points = [0,5,10,15,20,25, 30,35,40,45,50,55,60,65,70,75,80,85,90,120,180,240,270]\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Initialize list to store dictionaries for each row of the output DataFrame\n",
    "    output_data = []\n",
    "\n",
    "    # Check if the last time point exceeds the maximum time available in the DataFrame\n",
    "    if time_points[-1] > df['Study Time(sec)'].iloc[-1]:\n",
    "        time_points = [tp for tp in time_points if tp <= df['Study Time(sec)'].iloc[-1]]\n",
    "\n",
    "    # Iterate through time points\n",
    "    for time in time_points:\n",
    "        output_row = {'Time': time}\n",
    "\n",
    "        # Extract the value for each specified column at the current time point\n",
    "        plasmalyte = df.loc[df['Study Time(sec)'] == time, 'Cumulative Volume'].values[0]\n",
    "        norepi = df.loc[df['Study Time(sec)'] == time, 'Cumulative (Nor)epi Dose'].values[0]\n",
    "        vasopressin_counts = count_vasopressin_before(df, time_points, time)\n",
    "        Prox_Sys_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Prox_Sys_PowerLab_PC'].values[0]\n",
    "        Prox_Dia_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Prox_Dia_PowerLab_PC'].values[0]\n",
    "        Prox_Mean_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Prox_Mean_PowerLab_PC'].values[0]\n",
    "        Dist_Sys_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Sys_PowerLab_PC'].values[0]\n",
    "        Dist_Dia_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Dia_PowerLab_PC'].values[0]\n",
    "        Dist_Mean_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Mean_PowerLab_PC'].values[0]\n",
    "        Dist_Sys_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Sys_LPF_PowerLab_PC'].values[0]\n",
    "        Dist_Dia_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Dia_LPF_PowerLab_PC'].values[0]\n",
    "        Dist_Mean_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == time, 'Dist_Mean_LPF_PowerLab_PC'].values[0]\n",
    "\n",
    "        # Add the extracted values to the output row dictionary\n",
    "        output_row.update({\n",
    "            'Plasmalyte': plasmalyte,\n",
    "            'Norepi': norepi,\n",
    "            'Prox_Sys_PowerLab_PC': Prox_Sys_PowerLab_PC,\n",
    "            'Prox_Dia_PowerLab_PC': Prox_Dia_PowerLab_PC,\n",
    "            'Prox_Mean_PowerLab_PC': Prox_Mean_PowerLab_PC,\n",
    "            'Dist_Sys_PowerLab_PC': Dist_Sys_PowerLab_PC,\n",
    "            'Dist_Dia_PowerLab_PC': Dist_Dia_PowerLab_PC,\n",
    "            'Dist_Mean_PowerLab_PC': Dist_Mean_PowerLab_PC,\n",
    "            'Dist_Sys_LPF_PowerLab_PC': Dist_Sys_LPF_PowerLab_PC,\n",
    "            'Dist_Dia_LPF_PowerLab_PC': Dist_Dia_LPF_PowerLab_PC,\n",
    "            'Dist_Mean_LPF_PowerLab_PC': Dist_Mean_LPF_PowerLab_PC,\n",
    "            'Vasopressin_0': vasopressin_counts.get(0, 0),\n",
    "            'Vasopressin_1': vasopressin_counts.get(1, 0),\n",
    "            'Vasopressin_2': vasopressin_counts.get(2, 0),\n",
    "            'Vasopressin_3': vasopressin_counts.get(3, 0)\n",
    "        })\n",
    "\n",
    "        # Append the output row to the output data list\n",
    "        output_data.append(output_row)\n",
    "\n",
    "    # If the last specified time point exceeds the maximum time available in the DataFrame, include the last row\n",
    "    if time_points[-1] < df['Study Time(sec)'].iloc[-1]:\n",
    "        last_time = df['Study Time(sec)'].iloc[-1]\n",
    "\n",
    "        output_row = {'Time': last_time}\n",
    "\n",
    "        # Extract the value for each specified column at the last time point\n",
    "        plasmalyte = df.loc[df['Study Time(sec)'] == last_time, 'Cumulative Volume'].values[0]\n",
    "        norepi = df.loc[df['Study Time(sec)'] == last_time, 'Cumulative (Nor)epi Dose'].values[0]\n",
    "        vasopressin_counts = count_vasopressin_before(df, time_points, last_time)\n",
    "        Prox_Sys_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Prox_Sys_PowerLab_PC'].values[0]\n",
    "        Prox_Dia_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Prox_Dia_PowerLab_PC'].values[0]\n",
    "        Prox_Mean_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Prox_Mean_PowerLab_PC'].values[0]\n",
    "        Dist_Sys_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Sys_PowerLab_PC'].values[0]\n",
    "        Dist_Dia_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Dia_PowerLab_PC'].values[0]\n",
    "        Dist_Mean_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Mean_PowerLab_PC'].values[0]\n",
    "        Dist_Sys_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Sys_LPF_PowerLab_PC'].values[0]\n",
    "        Dist_Dia_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Dia_LPF_PowerLab_PC'].values[0]\n",
    "        Dist_Mean_LPF_PowerLab_PC = df.loc[df['Study Time(sec)'] == last_time, 'Dist_Mean_LPF_PowerLab_PC'].values[0]\n",
    "\n",
    "        # Add the extracted values to the output row dictionary\n",
    "        output_row.update({\n",
    "            'Plasmalyte': plasmalyte,\n",
    "            'Norepi': norepi,\n",
    "            'Prox_Sys_PowerLab_PC': Prox_Sys_PowerLab_PC,\n",
    "            'Prox_Dia_PowerLab_PC': Prox_Dia_PowerLab_PC,\n",
    "            'Prox_Mean_PowerLab_PC': Prox_Mean_PowerLab_PC,\n",
    "            'Dist_Sys_PowerLab_PC': Dist_Sys_PowerLab_PC,\n",
    "            'Dist_Dia_PowerLab_PC': Dist_Dia_PowerLab_PC,\n",
    "            'Dist_Mean_PowerLab_PC': Dist_Mean_PowerLab_PC,\n",
    "            'Dist_Sys_LPF_PowerLab_PC': Dist_Sys_LPF_PowerLab_PC,\n",
    "            'Dist_Dia_LPF_PowerLab_PC': Dist_Dia_LPF_PowerLab_PC,\n",
    "            'Dist_Mean_LPF_PowerLab_PC': Dist_Mean_LPF_PowerLab_PC,\n",
    "            'Vasopressin_0': vasopressin_counts.get(0, 0),\n",
    "            'Vasopressin_1': vasopressin_counts.get(1, 0),\n",
    "            'Vasopressin_2': vasopressin_counts.get(2, 0),\n",
    "            'Vasopressin_3': vasopressin_counts.get(3, 0)\n",
    "        })\n",
    "\n",
    "        # Append the output row to the output data list\n",
    "        output_data.append(output_row)\n",
    "\n",
    "    # Create output DataFrame\n",
    "    output_columns = ['Time', 'Plasmalyte', 'Norepi', 'Prox_Sys_PowerLab_PC', 'Prox_Dia_PowerLab_PC', 'Prox_Mean_PowerLab_PC',\n",
    "                      'Dist_Sys_PowerLab_PC', 'Dist_Dia_PowerLab_PC', 'Dist_Mean_PowerLab_PC',\n",
    "                      'Dist_Sys_LPF_PowerLab_PC', 'Dist_Dia_LPF_PowerLab_PC', 'Dist_Mean_LPF_PowerLab_PC',\n",
    "                      'Vasopressin_0', 'Vasopressin_1', 'Vasopressin_2', 'Vasopressin_3']\n",
    "    output = pd.DataFrame(output_data, columns=output_columns)\n",
    "    output.head(10)\n",
    "    # Save output DataFrame to \"Processed Data.xlsx\" with the sheet name as the filename\n",
    "    with pd.ExcelWriter('Processed Data.xlsx', mode='a', engine='openpyxl',if_sheet_exists='replace') as writer:\n",
    "        output.to_excel(writer, index=False, sheet_name=filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319c667",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNE-37.xlsx\n",
      "ERNE-60.xlsx\n",
      "ERNE-21.xlsx\n",
      "ERNE-56.xlsx\n",
      "ERNE-01.xlsx\n",
      "ERNE-17.xlsx\n",
      "ERNE-40.xlsx\n",
      "ERNE-41.xlsx\n",
      "ERNE-16.xlsx\n",
      "ERNE-57.xlsx\n",
      "ERNE-20.xlsx\n",
      "ERNE-61.xlsx\n",
      "ERNE-36.xlsx\n",
      "ERNE-50.xlsx\n",
      "ERNE-07.xlsx\n",
      "ERNE-11.xlsx\n",
      "ERNE-31.xlsx\n",
      "ERNE-66.xlsx\n",
      "ERNE-70.xlsx\n",
      "ERNE-27.xlsx\n",
      "ERDE-07.xlsx\n",
      "ERDE-06.xlsx\n",
      "ERNE-26.xlsx\n",
      "ERNE-71.xlsx\n",
      "ERNE-67.xlsx\n",
      "ERNE-30.xlsx\n",
      "ERNE-47.xlsx\n",
      "ERNE-10.xlsx\n",
      "ERNE-51.xlsx\n",
      "ERNE-44.xlsx\n",
      "ERNE-13.xlsx\n",
      "ERDE-09.xlsx\n",
      "ERNE-05.xlsx\n",
      "ERNE-52.xlsx\n",
      "ERNE-29.xlsx\n",
      "ERNE-68.xlsx\n",
      "ERNE-48.xlsx\n",
      "ERDE-05.xlsx\n",
      "ERNE-09.xlsx\n",
      "ERNE-25.xlsx\n",
      "ERNE-72.xlsx\n",
      "ERNE-64.xlsx\n",
      "ERNE-33.xlsx\n",
      "ERNE-32.xlsx\n",
      "ERNE-65.xlsx\n",
      "ERNE-24.xlsx\n",
      "ERNE-08.xlsx\n",
      "ERDE-04.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Create the path to the \"Raw Data\" folder within the current directory\n",
    "folder_path = os.path.join(current_directory, 'Raw Data')\n",
    "\n",
    "# Get a list of Excel files in the folder\n",
    "excel_files = list_excel_files(folder_path)\n",
    "\n",
    "# Process each Excel file\n",
    "for file in excel_files:\n",
    "    print(file)\n",
    "    # Read the Excel file and store the dataframes in a dictionary\n",
    "    dataframes = read_excel_files(folder_path, excel_files)\n",
    "#     print(dataframes)\n",
    "    # Process each dataframe and save to \"Processed Data.xlsx\"\n",
    "    for filename, df in dataframes.items():\n",
    "#         print(filename)\n",
    "#         print(df)\n",
    "        process_excel(filename, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa2a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76048004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Load the Excel file\n",
    "with pd.ExcelFile('Processed Data.xlsx') as xls:\n",
    "    # Get the sheet names\n",
    "    sheet_names = xls.sheet_names\n",
    "\n",
    "# Extract the numerical part from each sheet name\n",
    "numeric_part = [re.findall(r'\\d+', sheet_name) for sheet_name in sheet_names]\n",
    "\n",
    "# Sort the sheet names based on the numerical part\n",
    "sorted_sheet_names = [sheet_name for _, sheet_name in sorted(zip(numeric_part, sheet_names))]\n",
    "\n",
    "# Reorder the sheets and save to a new Excel file\n",
    "with pd.ExcelWriter('Processed Data In Order.xlsx', engine='openpyxl') as writer:\n",
    "    for sheet_name in sorted_sheet_names:\n",
    "        df = pd.read_excel('Processed Data.xlsx', sheet_name=sheet_name)\n",
    "        df.to_excel(writer, index=False, sheet_name=sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c500b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel files\n",
    "processed_data_file = \"Processed Data in Order.xlsx\"\n",
    "vaso_norepi_file = \"Vasopressin and Norepi.xlsx\"\n",
    "\n",
    "processed_data = pd.read_excel(processed_data_file, sheet_name=None)\n",
    "vaso_norepi_data = pd.read_excel(vaso_norepi_file)\n",
    "\n",
    "# Initialize an Excel writer object\n",
    "with pd.ExcelWriter(\"Processed_Data_with_Vasopressin.xlsx\") as writer:\n",
    "    # Iterate through every row of \"Vasopressin and Norepi.xlsx\" and find matching sheets\n",
    "    for index, row in vaso_norepi_data.iterrows():\n",
    "        parent_folder = row[\"Parent Folder\"]\n",
    "        if parent_folder in processed_data:\n",
    "            # Copy all data from corresponding sheet in \"Processed Data in Order.xlsx\"\n",
    "            processed_sheet = processed_data[parent_folder].copy()\n",
    "\n",
    "            # Multiply values where columns match\n",
    "            for column in processed_sheet.columns:\n",
    "                if column in vaso_norepi_data.columns:\n",
    "                    processed_sheet[column] *= row[column]\n",
    "\n",
    "            # Get \"Weight\" for the current row and perform division for specific columns\n",
    "            weight = row.get(\"Weight\", None)\n",
    "            if weight and weight != 0:  # Ensure weight is valid\n",
    "                if \"Plasmalyte\" in processed_sheet.columns:\n",
    "                    processed_sheet[\"Plasmalyte\"] /= weight\n",
    "                if \"Norepi\" in processed_sheet.columns:\n",
    "                    processed_sheet[\"Norepi\"] /= weight\n",
    "\n",
    "            # Calculate \"Total Vasopressin\"\n",
    "            vasopressin_columns = [f'Vasopressin_{i}' for i in range(4) if f'Vasopressin_{i}' in processed_sheet.columns]\n",
    "            if vasopressin_columns:\n",
    "                processed_sheet['Total Vasopressin'] = processed_sheet[vasopressin_columns].sum(axis=1)\n",
    "                # Calculate cumulative sum for \"Total Vasopressin\"\n",
    "                processed_sheet['Cumulative Vasopressin'] = processed_sheet['Total Vasopressin'].cumsum()\n",
    "\n",
    "            # Write the processed data to a new sheet with the name of the \"Parent Folder\"\n",
    "            processed_sheet.to_excel(writer, sheet_name=parent_folder, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13eef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Urine Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c2dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the \"drug concentrations\" directory if it doesn't exist\n",
    "output_dir = \"drug concentrations\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Read the categorization data from 'Experiment Tracker.xlsx'\n",
    "df = pd.read_excel('Experiment Tracker.xlsx', sheet_name=['T30 categorization', 'T60 categorization'])\n",
    "\n",
    "# Categorization at time=30\n",
    "group_10 = set(df['T30 categorization']['Group_10'].dropna())\n",
    "group_20 = set(df['T30 categorization']['Group_20'].dropna())\n",
    "group_30 = set(df['T30 categorization']['Group_30'].dropna())\n",
    "\n",
    "# Categorization at time=60\n",
    "full_occlusion = set(df['T60 categorization']['Full_Occlusion'].dropna())\n",
    "partial_occlusion = set(df['T60 categorization']['Partial_Occlusion'].dropna())\n",
    "no_occlusion = set(df['T60 categorization']['No_Occlusion'].dropna())\n",
    "\n",
    "# Load the processed data file\n",
    "file_path = \"Processed_Data_with_Vasopressin.xlsx\"\n",
    "xls = pd.ExcelFile(file_path)\n",
    "\n",
    "# Filter sheets that start with \"ERNE\" and not \"ERDE\"\n",
    "erne_sheets = [sheet for sheet in xls.sheet_names if sheet.startswith(\"ERNE\")]\n",
    "\n",
    "# List to store data before concatenation\n",
    "data_list = []\n",
    "\n",
    "# Loop through the filtered sheets and store them in the list\n",
    "for sheet in erne_sheets:\n",
    "    df = xls.parse(sheet)\n",
    "    required_columns = [\n",
    "        \"Time\", \"Cumulative Vasopressin\", \"Plasmalyte\", \"Norepi\",\n",
    "        \"Prox_Sys_PowerLab_PC\", \"Prox_Dia_PowerLab_PC\", \"Prox_Mean_PowerLab_PC\",\n",
    "        \"Dist_Sys_PowerLab_PC\", \"Dist_Dia_PowerLab_PC\", \"Dist_Mean_PowerLab_PC\",\n",
    "        \"Dist_Sys_LPF_PowerLab_PC\", \"Dist_Dia_LPF_PowerLab_PC\", \"Dist_Mean_LPF_PowerLab_PC\"\n",
    "    ]\n",
    "    \n",
    "    df = df[required_columns]\n",
    "    \n",
    "    # Remove rows where 'Time' is greater than 240\n",
    "    df = df[df[\"Time\"] <= 240]\n",
    "    \n",
    "    # Add a column to track the source sheet name\n",
    "    df[\"Source\"] = sheet\n",
    "    \n",
    "    # Append to the list\n",
    "    data_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "final_df = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# Load Urine Output Data\n",
    "urine_file = \"Urine Output.xlsx\"\n",
    "urine_df = pd.read_excel(urine_file, dtype=str)  # Read all values as strings to preserve text\n",
    "\n",
    "# Initialize the \"Urine Output\" column with blank values\n",
    "final_df[\"Urine Output\"] = \"N/A\"\n",
    "\n",
    "# Iterate through the urine output file to map values to the final_df\n",
    "for _, row in urine_df.iterrows():\n",
    "    time_point = row[\"Time\"]  # Get the time value from urine data\n",
    "    for col in urine_df.columns[1:]:  # Skip the \"Time\" column\n",
    "        subject_id = col  # Column names in urine file match \"Source\" in final_df\n",
    "        mask = (final_df[\"Time\"] == float(time_point)) & (final_df[\"Source\"] == subject_id)\n",
    "        final_df.loc[mask, \"Urine Output\"] = row[col]  # Assign urine output value as string\n",
    "\n",
    "# Save the final DataFrame to Excel\n",
    "output_file = \"Processed_Data_Output.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    final_df.to_excel(writer, sheet_name=\"All Data\", index=False)\n",
    "\n",
    "print(f\"Data successfully saved in '{output_file}' under sheet 'All Data' with Urine Output column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e1a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
